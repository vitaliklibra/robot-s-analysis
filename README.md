# Analysis file "robots.txt"

It web-application provides simple analysis file "robots.txt" on any site.

Its functions are the following:  
1) Checking the status code of the HTTP request status for file.  
2) Checking of existence of the file.  
3) Checking of file size.  
4) Checking of existence of directive "Host" in the file.  
5) Checking the number of directives "Host" in the file.  
6) Checking of existence of directive "Sitemap" in the file.

After the analysis shows a table with information about the file "robots.txt".
